{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "898bf218",
   "metadata": {},
   "source": [
    "# Етика у вештачкој интелигенцији"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51183924",
   "metadata": {},
   "source": [
    "У овој свесци говорићемо о:\n",
    "- изазовима са којима се сусрећу аутори интелигентних система,\n",
    "- отвореним етичким питањима која прате дебату о примени вештачке интелигенције,\n",
    "- могућим утицајима интелигентних система на друштво,\n",
    "- стратегијама и регулативама које се односе на примену вештачке интелигенције."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10b154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36c136ff",
   "metadata": {},
   "source": [
    "Захваљујући примени вештачке интелигенције (АИ) у многим аспектима је унапређен квалитет живота људи: унапређено је откривање лекова и дефинисање терапија, учињени су поузданијим системи за праћење природних катастрофа и алармирање, саобраћај је безбеднији због постојања паметних сензора и транспортних мрежа, а расположиви природни ресурси се могу рационалније и одрживије користити. Ипак, примену вештачке интелигенције прате и многа отворена питања. Пре свега, она су усмерена на поузданост (енгл. accountability), правичност (енгл. fairness) и транспарентност (енгл. transparency) рада оваквих система. Због тога су као одговор стигле и многобројне регулативе на нивоу појединачних земаља, али и шире, којима се прецизније дефинишу стратегије за праћење развоја и регулисање употреба оваквих система. Неке од њих су [Општа уредба о заштити података](https://gdpr.eu/tag/gdpr/) (енгл. GDPR), званични [извештај Европске комисије о изврсности и поверењу](https://ec.europa.eu/info/sites/default/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf), [УНЕСКО препоруке за примену вештачке интелигенције](https://unesdoc.unesco.org/ark:/48223/pf0000377897) и друге. Влада Републике Србије је крајем 2019. године усвојила [Стратегију развоја вештачке интелигенције у Републици Србији за период 2020-2025. године](https://www.srbija.gov.rs/tekst/437277). Ове активности прате и многи доприноси академије, индустрије и релевантних институција кроз научне радове и конференције које разматрају решавање уочених недостатака."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586b7d3",
   "metadata": {},
   "source": [
    "У наставку ћемо детаљније дискутовани о најважнијим отвореним питањима која прате развој и примену система заснованих на вештачкој интелигенцији. Отворена питања су део интересне сфере не само истраживача у домену вештачке интелигенције и рачунарских наука, дизајнера система и програмера, већ и филозофа, психолога, социолога, историчара, представника јавних политика и свих нас који ћемо користити ове системе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d27bc",
   "metadata": {},
   "source": [
    "<figure style='text-align: center'>\n",
    "    <img src='./assets/ai_izazovi.png'>\n",
    "    <figcaption> Изазови АИ система </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3253621",
   "metadata": {},
   "source": [
    "## Приватност и надгледање"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7651e6d",
   "metadata": {},
   "source": [
    "Предуслов за креирање интелигентних система је постојање велике количине доменских података. Тако, рецимо, да би се креирао систем који може да препоручи адекватан филм или књигу, мора постојати знање о корисниковом понашању и његовим преференцијама. Оваква знања долазе као агрегиране информације ранијих корисникових прегледа, куповина или активности. Према извештају Европске комисије, процењује се да ће доступна количина података која је у 2018. години  износила 33 зетабајта до 2025. године порасти на 175 зетабајта. Око 80% ових података налази се у *облаку*, у централизованим сервисима за обраду података. Стога се природно намећу питања о приватности:  који се све подаци чувају, где се чувају, ко има приступ подацима, када и под којим условима се могу дистрибуирати и за какве сврхе. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8069e",
   "metadata": {},
   "source": [
    "У многим ситуацијама камере се уграђују са циљем да унапреде безбедност грађана и детектују непримерена понашања и радње. Камере могу представљати и саставни део неких сервиса и услуга. На пример, мониторингом саобраћаја могуће је проценити оптерећеност одређених деоница и затим прилагодити динамику рада семафора и помоћи у смањењу гужви. Без обзира на мотивацију за њихово постављање, захваљујући интелигентним системима за препознавање лица и анализу видеа, могуће је реконструисати активности грађана, пратити њихове руте кретања и навике које имају. Постоје земље у којима су камерама покривене готово све јавне површине и чији се снимци, необично, користе за рачунање оцена грађана: пожељне активности попут посете парку или бављење спортским активностима у току викенда доносе позитивне поене, док мање пожељне активности попут ноћног изласка носе негативне поене. Грађани са већим оценама имају бенефиције као што су погоднији стамбени кредити или приоритети за вртиће. Овакви примери остављају простор за страх од дигиталног ропства (енгл. digital slavery) и подсећају на питања елементарних људских права, слобода избора и кретања.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb34cbfa",
   "metadata": {},
   "source": [
    "На нивоу Европске уније је 2016. године усвојена Општа уредба о заштити података и приватности која важи у свим земљама Европске уније и Европске економске зоне. Овом уредбом је прецизно дефинисано шта су то лучни подаци, каква права се на њих полажу, у које сврхе и када се могу користити, као и кавке су последице по оне који се огреше о поштовање ових процедура. Србија, као кандидат за придруживање Европској унији, је уз мање измене усвојила овај закон и он је на снази од 2018. године. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf0940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af9e5bea",
   "metadata": {},
   "source": [
    "### Пристрасност, правичност и транспарентност"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ba45c",
   "metadata": {},
   "source": [
    "Велике количине података које се користе за развој интелигентних система рефлектују и оно што системи могу да науче. На пример, системи за препознавање лица могу са различитом тачношћу да препознају лица белаца и црнаца, док системи за генерисање текста могу да генеришу увредљиве и непримерене садржаје усмерене искључиво ка одређеним верским групама. На овај начин, интелигентни системи могу да продубе постојеће стереотипе и предрасуде средине и угроже и повреде одређене групације људи. Због тога је важно да системи буду непристрасни (eng. unbiased).   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97b58e",
   "metadata": {},
   "source": [
    "Одсуство пристрасности према појединцима или одређеним групама је циљ правичних интелигентних система (eng. fairness). На пример, систем који упарује расположиве позиције за посао и потенцијалне кандидате треба да да свима једнаку прилику без обзира на пол, старосну доб или порекло. Слично, пожељно је да претраживачке машине приказују разноврсне проналаске који представљају опште мњење, а не строго персонализоване садржаје који могу учврстити нечије погрешне ставове или сумње. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312dc002",
   "metadata": {},
   "source": [
    "У неким доменима примене интелигентних система као што су судство или здравство, може бити посебно важна транспарентност (енгл. transparency) система. Транспарентност се доводи у везу са објашњивошћу корака система који су претходили коначном резултату. На пример, систем који се користи као подршка дијагностиковању у некој болници може се дизајнирати тако да се сви кораци могу лако интерпретирати и разумети од стране лекара. Тренутно неки од најперформантнијих система у домену обраде слика или текста функционишу по принципу црне кутије (енгл. black-box) без сасвим јасних закључака каква знања ови системи имају и на који начин су изведена. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d91f1",
   "metadata": {},
   "source": [
    "Заједница која активно истражује у домену система заснованих на вештачкој интелигенцији је свесна побројаних недостатака. Стога се улажу велики напрони академије и индустрије да се дефинишу боље метрике, креирају релевантни скупови за тестирање, развију робусни алгоритми и алати који могу допринети бољем анализирању и праћењу развоја оваквих система."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbeab05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "895e6a76",
   "metadata": {},
   "source": [
    "## Одговорност АИ система"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04301d1d",
   "metadata": {},
   "source": [
    "Интелигентни системи се креирају тако да доносе различите врсте одлука - да процене да ли је текстуална порука пожељна или непожељна, да ли ће цена акција на берзи сутра скочити или не, да ли треба зауставити аутономно возило или повећати брзину. Због свих горенаведених разлога, интелигентни системи могу да донесу погрешну одлуку. Стога је важно питање чија је одговорност за случај да систем погреши: да ли је то одоговорност креатора скупа података за учење и тестирање, оних који су осмислили и дизајнирали систем, оних који су имплементирали систем или оних који поседују систем. Лабораторија за интердисциплинарне студије при МИТ универзитету је спровела врло опсежно испитивање јавног мњења за случај аутономних возила у готово свим земљама света. Упитници су се састојали од разноврсних питања која су разматрала исходе несрећа услед отказивања система, а испитаници су могли да одаберу најбољу одлуку коју систем треба да донесе. Резултати ове студије указују да не постоји глобална усаглашеност и да су одлуке које системи треба да доднесу врло супилне и често тешке и опречне и за човека. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ce970",
   "metadata": {},
   "source": [
    "Питање одговорности је подједнако важно и за приватни и за јавни сектор и продубљује причу о транспарентности система - ова особина дозвовољава да се провери да ли су одлуке донесене у складу са процедуралним и другим стандардима и да ли поштују све законске рестрикције.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95333508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1166964c",
   "metadata": {},
   "source": [
    "## Робусност АИ система "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095840e",
   "metadata": {},
   "source": [
    "На причу о позуданости интелигентних система наслања се и прича о робусности. Робусност система осликава промену резултата уколико се систему поред очекиваног улаза проследи и шум. На пример, систем који користи камере за идентификацију запослених се може збунити и погрешити уколико запослени стави наочаре или промени фризуру. Слично, системи за аутоматско препознавање саобраћајних знакова могу погрешити уколико је табла закривљена или уколико на њу слети птица. Оваква искуства су утицала на дизајнирање нешто другачијих процедура за обучавање и евалуацију система не би ли се предупредила потенцијална злонамерна употреба."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c23190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70ec958c",
   "metadata": {},
   "source": [
    "## Одржива вештачка интелигенција и демократизација система"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab33d52",
   "metadata": {},
   "source": [
    "Осим података, за креирање интелигентних система потребни су и специфични хардверски ресурси који имају своје енергетске захтеве и директан утицај на животну средину. На пример, да би се одредили оптимални хиперпараметри и обучио велики трансформер, специфична дубока неуронска мрежа, емитује се око 626 хиљада фунти (1 фунта износи 0,453 килограма) карбон диоксида (CO2). Упоредивости ради, у току животног века један аутомобил емитује око 126 хиљада функти карбон диоксида. Уз ово, обучавање једног оваквог трансформера може бити јако скупо. На пример, да би се обучио трансформер који се зове БЕРТ који долази из компаније Гугл, коришћене су специјалне процесне јединице (ТПУ), укупно њих 16, четири дана без престанка. Уз просечну цену око 4,5 долара по сату за коришћење једног оваквог сервиса, цена обучавања модела је износила 6. 912 долара. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d06be",
   "metadata": {},
   "source": [
    "Овакво стање ствари прате питања одрживости потрошње ресурса, као и питање демократизације: ко су институције које располажу специјализованим хардвером и ко све може да изнесе овако високу цену развоја модела. Намеће се утисак да неће сви моћи равноправно да допринесу својим идејама."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5abd959",
   "metadata": {},
   "source": [
    "Научна заједница покушава да одговори на ова питања развојем парадигми трансфера знања тако да се једном обучени модели могу више пута користити. Такође, научна заједница подстиче на развој рачунски ефикаснијих алгоритама и хардвера који захтева мање енергије."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2fb137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "814695c4",
   "metadata": {},
   "source": [
    "## Утицај вештачке интелигенције на друштво"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b631d",
   "metadata": {},
   "source": [
    "Системи засновани на вештачкој интелигенцији могу помоћи да се боље сагледају и лакше пронађу решења за многе изазове са којима се човечанство суочава. Пример који смо сви искусили тиче се COVID-19 пандемије, њеног праћења кроз анализу велике количине актуелних података и научне литературе зарад бржег проналажења терапија и вакцина."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f80dd9",
   "metadata": {},
   "source": [
    "Са друге стране, ови системи имају капацитет да продубе неједнакости и поделе у друштву. Према УНЕСКО статистикама, процењује се да ће се до краја 2022. године остварити зарада од око 4 трилиона долара захваљујући применама АИ система. Такође, наводи се и да ће до 2030. године око 70% тржишта припадати Кини и Северној Америци остављајући јако мало простора земљама у развоју да унапреде и приближе своје буџете или утичу на дизајнирање ових система. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bed49",
   "metadata": {},
   "source": [
    "Аутоматизација послова може довести и до потреба за мањом радном снагом. На пример, ланац продавница АмазонГо не запошљава особље за рад на касама: продавнице су опремљене камерама на плафону које прате појединачне купце и производе које они купују и аутоматски, на изласку из продавнице, скидају средства са њиховог рачуна. Овакав вид куповине елиминише неугодности попут чекања у редовима и омогућава ефикаснију и брзу куповину. Са становништа зарада, овакве продавнице упркос већим улагањима у опрему и системе за праћење могу да искористе свој специфични вид организације за већи профит и мање дневне трошкове. Директна последица ове организације је и неједнака могућности за зараду и неједнака дистрибуција укупног капитала. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d286d94",
   "metadata": {},
   "source": [
    "Системи засновани на вештачкој интелигенцији већ свакодневно утичу на начин на који добијамо и користимо информације, комуницирамо и дружимо се. Садржаји који сервирају претраживачке машине, друштвене мреже и системи препорука су персонализовани, а неретко су одабрани и тако да добију нашу пажњу и фокус. Иако често корисни, овако дизајнирани системи могу злоупотребити пажњу осетљивих група као што су, на пример, деца и угрозити њихов развој и безбедност. Зато је све више иницијатива које се групишу око вештачке интелигенције усредсређене на човека (енгл. human-centered AI) која види примену ових технологија за опште добро човечанства, а не супротно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1fabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e44c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994595c1",
   "metadata": {},
   "source": [
    "## Питања и задаци за вежбу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b63089",
   "metadata": {},
   "source": [
    "1. Покушајте да се сетите неког медијски пропраћеног догађаја који су тиче примене вештачке интелигенције. \n",
    "\n",
    "2. Које су предности примене интелигентних система у области којом се бавите? Који ризици долазе са овим применама?\n",
    "\n",
    "3. Шта су најдалекосежније идеје које имате у вези са применом вештачке интелигенције?\n",
    "\n",
    "4. Да ли сте чули за дубоке фалсификате (енгл. deepfakes) тј. лажне слике и фабриковане видео снимке? Покушајте да пронађете неки на вебу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748d5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
